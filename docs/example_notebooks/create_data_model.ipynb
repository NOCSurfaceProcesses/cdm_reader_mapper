{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to create a data model"
   ]
  }, 
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will create and apply a new **data model/schema** to a raw `.imma` file, using the [mdf_reader](https://git.noc.ac.uk/iregon/mdf_reader) tool. We will add supplemental metadata to the basic `imma1` data model and display supplemental data as a pandas dataframe.\n",
    "\n",
    "Lets first import all the tools that we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "from collections import OrderedDict\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "try:\n",
    "    from importlib.resources import files as get_files\n",
    "except ImportError:\n",
    "    from importlib_resources import files as get_files\n",
    "\n",
    "from cdm_reader_mapper import mdf_reader, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `mdf_reader` tool comes with data model templates of `.json` files, that we can use to build our models. For more information see the following [manual](https://git.noc.ac.uk/iregon/mdf_reader/-/blob/master/docs/User_manual.docx)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf_reader.properties.supported_data_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the manual, ICOADS data stored with the [IMMA format](https://icoads.noaa.gov/e-doc/imma/R3.0-imma1.pdf) represents a complex data model, since the data includes blocks of sections which are exclusive to certain DCK's (e.g. data coming from the NOAA National Climatic Data Center (NCDC) TD-11 formats). Most of the ICOADS data however will need a **schema** based on the `imma1.json` format.\n",
    "\n",
    "Lets try to build our own **schema** based on this template for a new dck. In this notebook we will organise the data and metadata from the **US Maury collection** that corresponds to `source/dck 069-701`.\n",
    "\n",
    "1. First lets read a raw `.imma` file from dck 701 as an example, for a subset of the data collected in April/1845.\n",
    "\n",
    "One should note that a full schema for this deck already exists: `\"imma1_d701\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test data\n",
    "data = test_data.test_069_701\n",
    "\n",
    "data_raw = mdf_reader.read(data.get(\"source\"), data_model=\"imma1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now look at the supplementary data column for this data, i.e.: the `\"c99\"` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.data[\"c99\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `c99` column is a bit messy. Here, we will need to separate the Supplemental Metadata ingested in ICOADS as an entire string and sort each row out according to the source & dck documentation.\n",
    "\n",
    "2. We then need to make a new data model or **schema** which can then be used by the `mdf_reader` module. For this we create a schema with the name `imma1_d701`. For the purposes of this notebook we will create this schema in a temporary directory.\n",
    "3. In this directory we will need to add a `.json` file with the same name. This `imma1_d701.json` file will contain all the data model information with instructions on how to subdivide the metadata added to `c99`. The name of the file is `imma1_d701.json` because the data model for this deck is based on the `imma1` template shown above, but the `c99` will be further subdivided into other columns/sections. We will start with a copy of the original `\"imma1\"` schema and add elements to the `c99` section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a copy of the \"imma1\" schema\n",
    "schema: OrderedDict = mdf_reader.schemas.read_schema(schema_name=\"imma1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the directory where we store the schema\n",
    "my_model_name = \"imma1_d701\"\n",
    "tmp_dir = TemporaryDirectory()\n",
    "my_model_path = os.path.join(tmp_dir.name, my_model_name)\n",
    "os.mkdir(my_model_path)\n",
    "print(my_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should now look at the documentation for this deck, to see if we can parse the `c99` section.\n",
    "\n",
    "From the US Maury collection [ICOADS documentation](https://icoads.noaa.gov/e-doc/other/transpec/maury/maury_transpec), we find out that the `c99` for this deck is composed of the following sections:\n",
    "\n",
    "- Data\n",
    "- Header information\n",
    "- Quality control information (qc)\n",
    "\n",
    "In this example we will only look to make a few new elements for demonstration purposes. A full schema file already exists for deck 701, we are not looking to duplicate that in full here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Data stored in the supplemental attachment consisted of the entire data record\n",
    "(173 characters); followed by a selection of fields from, or derived from, the\n",
    "associated header record (through character 241); and selected fields from the\n",
    "qc file (total 250 characters):\n",
    "  # Pos.     Total #  Field  Record\n",
    "    range    of pos.   name    type  Description of field (of derived field)\n",
    "--- -------  -------  -----  ------  ----------------------------------------\n",
    "  1 1-7         7     cvoyd    data  voyage number\n",
    "... ...               ...       ...  ...\n",
    " 47 172-173     2     cmvq     data  magnetic variation QC indicator\n",
    " NA 174-175     2     cts2   header  (fr ship type, ctship, according to [5])\n",
    "  4 176-177     2     cft    header  form type\n",
    "  5 178-193    16     comm   header  commander (first 16 positions only) [6]\n",
    "  6 194-217    24     cfr    header  from city\n",
    "  7 218-241    24     cto    header  to city\n",
    "  2 242-246     5     qc2    qc      reel sequence number\n",
    "  5 247-248     2     qc5    qc      day  (local time) (99 indicates missing)\n",
    "  6 249-250     2     qc6*   qc      hour (local time) (99 indicates missing)\n",
    "--- -------  -------  -----  ------  ----------------------------------------\n",
    "* Whenever qc6 was 24, zero was inadvertently written out to the supplemental\n",
    "attachment.  This resulted from an error in the conversion program, but can\n",
    "be fixed by interpretation of hour zero as hour 24 of qc5 + 1 (as noted in [2],\n",
    "qc6 originally ranged 1-24, with 24 signifying hour 0 of the next day.  As\n",
    "intended, qc5 was included in the supplementary attachment in original form.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `c99_sentinal` section identifies where in the data, we will have a new section. In this case we will have a new section corresponding to Supplemental Metadata.\n",
    "\n",
    "In our example this supplemental metadata will come from the documentation of the US Maury collection stored in the [ICOADS website](https://icoads.noaa.gov/e-doc/other/transpec/maury/maury_transpec).\n",
    "\n",
    "4. We will need to add the metadata information from the website inside that `c99_sentinal` section and create as many sections as the data requires.\n",
    "\n",
    "> sentinal: section identifier\n",
    "> applies to: format.fixed_width\n",
    "> is mandatory: it is not mandatory if the section is unique, unique in a parsing_order block, or\n",
    "> part of a sequential parsing_order block.\n",
    "> type: string\n",
    "> comments: the element bearing the sentinal needs to be, additionally, declared in the\n",
    "> elements block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c99 = data_raw.data[\"c99\"]\n",
    "line = c99.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentinal = 5\n",
    "part_1 = line[0:5]\n",
    "part_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cvoyd voyage number = 7\n",
    "part_2 = line[5 : 5 + 7]\n",
    "part_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date = 10\n",
    "part_3 = line[12 : 12 + 10]\n",
    "part_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the custom model\n",
    "\n",
    "We now make the adjustments to the schema to parse the sentinal, voyage number, and date fields. The rest can be skipped for this example.\n",
    "\n",
    "Here we add to the dictionary containing the `\"imma1\"` schema loaded earlier, we then save that to a `json` file in our model directory.\n",
    "\n",
    "Note that we need to use an `OrderedDict` here, since the ordering of the fields is important, a standard python `dict` is un-ordered and may shuffle the elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema[\"sections\"][\"c99\"][\"header\"][\"sentinal\"] = \"99 0 \"\n",
    "schema[\"sections\"][\"c99\"][\"header\"][\"disable_read\"] = False\n",
    "schema[\"sections\"][\"c99\"][\"header\"][\"field_layout\"] = \"fixed_width\"\n",
    "schema[\"sections\"][\"c99\"][\"header\"][\"length\"] = 250 + 5  # Sentinal length\n",
    "schema[\"sections\"][\"c99\"][\"elements\"] = OrderedDict(\n",
    "    {\n",
    "        \"sentinal\": {\n",
    "            \"description\": \"attachment sentinal\",\n",
    "            \"field_length\": 5,\n",
    "            \"column_type\": \"str\",\n",
    "        },\n",
    "        \"cvoyd\": {\n",
    "            \"description\": \"Voyage Information\",\n",
    "            \"field_length\": 7,\n",
    "            \"column_type\": \"str\",\n",
    "        },\n",
    "        \"year\": {\n",
    "            \"description\": \"Year\",\n",
    "            \"field_length\": 4,\n",
    "            \"column_type\": \"uint16\",\n",
    "        },\n",
    "        \"month\": {\n",
    "            \"description\": \"Month\",\n",
    "            \"field_length\": 2,\n",
    "            \"column_type\": \"uint8\",\n",
    "        },\n",
    "        \"day\": {\n",
    "            \"description\": \"Day\",\n",
    "            \"field_length\": 2,\n",
    "            \"column_type\": \"uint8\",\n",
    "        },\n",
    "        \"rest\": {\n",
    "            \"description\": \"Remaining c99 string\",\n",
    "            \"field_length\": 235,  # 250 - (8 + 7)\n",
    "            \"column_type\": \"str\",\n",
    "        },\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_object = json.dumps(schema, indent=2)\n",
    "\n",
    "with open(os.path.join(my_model_path, my_model_name + \".json\"), \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final component of a model for the `mdf_reader` module is the `code_tables`. These are the tables that relate `key` columns to their values. For this example we will copy the code tables from the original `imma1` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_tables_path = get_files(\n",
    "    \".\".join([mdf_reader.properties._base, \"code_tables\", \"imma1\"])\n",
    ")\n",
    "shutil.copytree(code_tables_path, os.path.join(my_model_path, \"code_tables\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we feed this new data model to the `mdf_reader.read` function. To use our custom schema we need to specify the `data_model_path` argument, rather than the `data_model` argument used earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = mdf_reader.read(data.get(\"source\"), data_model_path=my_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And magically all the messy string is _partially_ separated!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.data[\"c99\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also quickly verify that the original fields are parsed in the same way, here we are just verifying that the columns in the `core` section are unchanged following the changes made to the schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in data_new.data[\"core\"].columns:\n",
    "    assert data_new.data[\"core\"][c].equals(data_raw.data[(\"core\", c)])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
